# crew-ai-slm-local

**crew-ai-slm-local** Ã© um projeto para orquestraÃ§Ã£o de agentes autÃ´nomos utilizando o framework CrewAI e modelos de linguagem locais (SLMs), como Ollama ou servidores compatÃ­veis com a API OpenAI. O objetivo Ã© criar pipelines colaborativos de IA, com agentes especializados, rodando totalmente offline ou em ambientes controlados, garantindo privacidade e flexibilidade.

---

## âœ¨ VisÃ£o Geral

Este repositÃ³rio demonstra como estruturar uma equipe ("crew") de agentes inteligentes, cada um com papÃ©is e tarefas especÃ­ficas, utilizando modelos de linguagem hospedados localmente. Ã‰ ideal para experimentaÃ§Ã£o, pesquisa, automaÃ§Ã£o de geraÃ§Ã£o de conteÃºdo e integraÃ§Ã£o de SLMs em fluxos de trabalho reais.

---

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ agents/               # DefiniÃ§Ã£o dos agentes autÃ´nomos (ex: pesquisador, escritor)
â”‚   â”œâ”€â”€ researcher.py
â”‚   â””â”€â”€ writer.py
â”œâ”€â”€ docs/                 # DocumentaÃ§Ã£o adicional
â”‚   â””â”€â”€ readme-select-models-for-use.md
â”œâ”€â”€ main.py               # Script principal para orquestraÃ§Ã£o dos agentes e execuÃ§Ã£o das tarefas
â”œâ”€â”€ models/               # Scripts utilitÃ¡rios para setup dos modelos locais
â”‚   â”œâ”€â”€ setup-models.sh
â”‚   â””â”€â”€ setup_install_ollama.sh
â”œâ”€â”€ outputs/              # SaÃ­das geradas (ex: artigos finais)
â”‚   â””â”€â”€ final_article.md
â”œâ”€â”€ requirements.txt      # DependÃªncias do projeto
â”œâ”€â”€ tasks/                # DefiniÃ§Ã£o das tarefas para os agentes
â”‚   â”œâ”€â”€ research_task.py
â”‚   â”œâ”€â”€ structure_task.py
â”‚   â””â”€â”€ writing_task.py
â””â”€â”€ utils/                # UtilitÃ¡rios e wrappers para integraÃ§Ã£o com modelos e prompts
    â”œâ”€â”€ ollama_wrapper.py
    â””â”€â”€ prompts.py
```

---

## ğŸš€ Como Usar

### 1. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Configure e instale os modelos locais

VocÃª pode usar os scripts em `models/` para instalar e configurar o Ollama ou outros SLMs locais:

```bash
bash models/setup_install_ollama.sh
bash models/setup-models.sh
```

Consulte o arquivo [`docs/readme-select-models-for-use.md`](docs/readme-select-models-for-use.md) para detalhes sobre seleÃ§Ã£o e configuraÃ§Ã£o de modelos.

### 3. Execute o pipeline principal

```bash
python main.py
```

O resultado final serÃ¡ salvo em `outputs/final_article.md`.

---

## ğŸ§© Componentes Principais

- **agents/**: Define os agentes, como o pesquisador (`researcher.py`) e o escritor (`writer.py`), cada um com responsabilidades e habilidades especÃ­ficas.
- **tasks/**: Especifica as tarefas a serem executadas pelos agentes (pesquisa, estruturaÃ§Ã£o, redaÃ§Ã£o).
- **utils/**: Inclui wrappers para integraÃ§Ã£o com modelos locais (ex: `ollama_wrapper.py`) e prompts customizados.
- **models/**: Scripts para setup e instalaÃ§Ã£o dos modelos de linguagem.
- **outputs/**: DiretÃ³rio para armazenar as saÃ­das geradas pelo pipeline.

---

## ğŸ› ï¸ CustomizaÃ§Ã£o

- **Adicionar novos agentes**: Crie um novo arquivo em `agents/` e defina o comportamento desejado.
- **Adicionar/alterar tarefas**: Edite ou crie novos arquivos em `tasks/`.
- **Alterar modelo de linguagem**: Modifique o wrapper em `utils/ollama_wrapper.py` para apontar para o endpoint/modelo desejado.

---

## ğŸ“ Boas PrÃ¡ticas

- Mantenha os scripts de setup de modelos atualizados conforme novas versÃµes dos SLMs.
- Utilize o diretÃ³rio `outputs/` para versionar e analisar as saÃ­das dos agentes.
- Documente agentes e tarefas para facilitar a colaboraÃ§Ã£o.
- Use ambientes virtuais para isolar as dependÃªncias do projeto.

---

## ğŸ“š DocumentaÃ§Ã£o

- [docs/readme-select-models-for-use.md](docs/readme-select-models-for-use.md): Guia para seleÃ§Ã£o e configuraÃ§Ã£o de modelos de linguagem locais.

---

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou pull requests com melhorias, correÃ§Ãµes ou novas funcionalidades.

---

## âš–ï¸ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

---

> Desenvolvido para facilitar a experimentaÃ§Ã£o e integraÃ§Ã£o de agentes inteligentes com modelos de linguagem locais! ğŸš€

---
Answer from Perplexity: pplx.ai/share